{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdc4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "# from keras.applications import DenseNet121\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ee5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'Training'\n",
    "test_data_path = 'Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdf197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a03bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process images in a folder\n",
    "def process_images(folder_path, images_list, labels_list):\n",
    "    for class_folder in os.listdir(folder_path):\n",
    "        class_path = os.path.join(folder_path, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            image = image.convert('L')\n",
    "            \n",
    "            # Resize the image to 64x64\n",
    "            image = image.resize((64, 64))\n",
    "            \n",
    "            # Convert the image to a NumPy array\n",
    "            image_array = np.array(image)\n",
    "            \n",
    "            # Normalize the image data (if needed)\n",
    "            image_array = image_array / 255.0\n",
    "            \n",
    "            # Append the processed image and its label to the lists\n",
    "            images_list.append(image_array)\n",
    "            labels_list.append(class_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb2965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training images\n",
    "process_images(train_data_path, x_train, y_train)\n",
    "\n",
    "# Process testing images\n",
    "process_images(test_data_path, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "030751c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr=[]\n",
    "x_ts=[]\n",
    "y_tr=[]\n",
    "y_ts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84db6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.array(x_train)\n",
    "y_tr = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51fd9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts = np.array(x_test)\n",
    "y_ts = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6a8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the lists to NumPy arrays\n",
    "# x_train = np.array(x_train)\n",
    "# x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2d2b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84096, 64, 64), (84096,), (21024, 64, 64), (21024,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape,y_tr.shape,x_ts.shape,y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766d6034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class labels to categorical format using one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_tr)\n",
    "y_test_encoded = label_encoder.transform(y_ts)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_tr1 = onehot_encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
    "y_ts1 = onehot_encoder.transform(y_test_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8d69b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84096, 64, 64), (84096, 5), (21024, 64, 64), (21024, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape,y_tr1.shape,x_ts.shape,y_ts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50825bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data by adding an extra dimension\n",
    "x_tr = np.expand_dims(x_tr, axis=-1)\n",
    "x_ts = np.expand_dims(x_ts, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef16783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84096, 64, 64, 1), (84096, 5), (21024, 64, 64, 1), (21024, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape,y_tr1.shape,x_ts.shape,y_ts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d846757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84ce67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 21, 21, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 21, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 853,989\n",
      "Trainable params: 853,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the shape of the input data\n",
    "input_shape = (64, 64, 1)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 5\n",
    "\n",
    "# Define the 2D CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(6, 6), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(4, 4), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# Fully connected\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f879cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e084847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1314/1314 [==============================] - 143s 108ms/step - loss: 0.8754 - accuracy: 0.6795\n",
      "Epoch 2/50\n",
      "1314/1314 [==============================] - 144s 110ms/step - loss: 0.4625 - accuracy: 0.8273\n",
      "Epoch 3/50\n",
      "1314/1314 [==============================] - 146s 111ms/step - loss: 0.3564 - accuracy: 0.8673\n",
      "Epoch 4/50\n",
      "1314/1314 [==============================] - 143s 109ms/step - loss: 0.3053 - accuracy: 0.8845\n",
      "Epoch 5/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.2746 - accuracy: 0.8951\n",
      "Epoch 6/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.2499 - accuracy: 0.9032\n",
      "Epoch 7/50\n",
      "1314/1314 [==============================] - 140s 107ms/step - loss: 0.2345 - accuracy: 0.9098\n",
      "Epoch 8/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.2175 - accuracy: 0.9146\n",
      "Epoch 9/50\n",
      "1314/1314 [==============================] - 142s 108ms/step - loss: 0.2053 - accuracy: 0.9208\n",
      "Epoch 10/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1986 - accuracy: 0.9234\n",
      "Epoch 11/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1920 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1854 - accuracy: 0.9292\n",
      "Epoch 13/50\n",
      "1314/1314 [==============================] - 149s 113ms/step - loss: 0.1791 - accuracy: 0.9314\n",
      "Epoch 14/50\n",
      "1314/1314 [==============================] - 140s 106ms/step - loss: 0.1715 - accuracy: 0.9339\n",
      "Epoch 15/50\n",
      "1314/1314 [==============================] - 143s 109ms/step - loss: 0.1677 - accuracy: 0.9343\n",
      "Epoch 16/50\n",
      "1314/1314 [==============================] - 143s 109ms/step - loss: 0.1621 - accuracy: 0.9376\n",
      "Epoch 17/50\n",
      "1314/1314 [==============================] - 142s 108ms/step - loss: 0.1620 - accuracy: 0.9372\n",
      "Epoch 18/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1548 - accuracy: 0.9408\n",
      "Epoch 19/50\n",
      "1314/1314 [==============================] - 143s 109ms/step - loss: 0.1524 - accuracy: 0.9405\n",
      "Epoch 20/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1510 - accuracy: 0.9410\n",
      "Epoch 21/50\n",
      "1314/1314 [==============================] - 141s 107ms/step - loss: 0.1482 - accuracy: 0.9431\n",
      "Epoch 22/50\n",
      "1314/1314 [==============================] - 141s 108ms/step - loss: 0.1457 - accuracy: 0.9436\n",
      "Epoch 23/50\n",
      "1314/1314 [==============================] - 141s 108ms/step - loss: 0.1456 - accuracy: 0.9447\n",
      "Epoch 24/50\n",
      "1314/1314 [==============================] - 142s 108ms/step - loss: 0.1406 - accuracy: 0.9464\n",
      "Epoch 25/50\n",
      "1314/1314 [==============================] - 141s 108ms/step - loss: 0.1405 - accuracy: 0.9460\n",
      "Epoch 26/50\n",
      " 765/1314 [================>.............] - ETA: 59s - loss: 0.1308 - accuracy: 0.9504"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "history=model.fit(x_tr, y_tr1, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, accuracy = model.evaluate(x_ts, y_ts1, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4affc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76094272",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN=np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f21795",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts1_1=np.argmax(y_ts1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a72fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b307e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_ts1_1, prediction_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533857e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_ts1_1, prediction_NN)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b85e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# print(class_labels)\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4']\n",
    "print(classification_report(y_ts1_1, prediction_NN, target_names=target_names,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('M2_copy_all_imgs_2lyr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0996c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ded41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91630769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_dict = {0: 'Class 0',\n",
    "#               1: 'Class 1',\n",
    "#               2: 'Class 2',\n",
    "#               3: 'Class 3',\n",
    "#               4: 'Class 4'}\n",
    "\n",
    "# multiclass = np.array([[11825,     7,     3,    71,    20],\n",
    "#                        [149,  1293,     0,    19,   116],\n",
    "#                        [19,     0,  1509,     0,     8],\n",
    "#                        [178,     0,     0,   973,   110],\n",
    "#                        [9,     8,     0,    56,  4651]])\n",
    "\n",
    "# fig, ax = plot_confusion_matrix(\n",
    "#     conf_mat=multiclass,\n",
    "#     class_names=class_dict.values(),show_normed=True,colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
